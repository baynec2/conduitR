################################################################################
# Making a readme
################################################################################
protein_info_fp <- snakemake@input[[1]]
output_fp <- snakemake@output[["md"]]
html_fp <- snakemake@output[["html"]]

# Testing
#protein_info_fp = "user_input/00_database_resources/02_protein_info.txt"
#output_fp = "user_input/00_database_resources/README.md"

# Get dynamic information
current_date <- Sys.Date() # Current system date
system_name <- Sys.info()["sysname"] # System name (e.g., Windows, Linux, Darwin)
user_name <- Sys.info()["user"] # User name on the system
# Get infomation from protein_info_fp
protein_info <- readr::read_delim(protein_info_fp)
n_protein <- protein_info$protein_id |> length()
n_organism <- protein_info$species |>
  unique() |>
  length()

# Create the README content with dynamic information
readme_content <- c(
  "# Conduit Database Resources",
  "",
  "This directory contains database resources generated using the **Conduit** platform for metaproteomic analysis.",
  "",
  paste0("## Database Generation Details\nThis database was generated on **", current_date, "** by user **", user_name, "** using a ", system_name, " system."),
  paste0("The database includes proteome information for **", n_protein, "** proteins derived from **", n_organism, "** species"),
  "",
  "These resources can be reused for additional analyses within Conduit for experiments containing the same search space.",
  "To do so, add the entire directory (output/00_database_resources) to the `user_input` directory. This prevents the need for regeneration, reducing overall processing time.",
  "",
  "## Files and Their Contents",
  "",
  "### **00_database.fasta**",
  "This file was created by downloading reference proteomes from the **UniProt API** based on **NCBI taxonomy IDs** supplied by the user in `organisms.txt`.",
  "- If a **reference proteome** was available, it was downloaded.",
  "- If no reference proteome existed, the first proteome returned by the API was used.",
  "- All proteomes were concatenated into `00_database.fasta`.",
  "",
  "### **01_taxonomy.txt**",
  "This file was generated by querying the **NCBI API** for taxonomic information corresponding to the taxonomy IDs in `organisms.txt`.",
  "",
  "### **02_protein_info.txt**",
  "This file was created by extracting information from `00_database.fasta` and formatting it into a structured table. It includes:",
  "- Protein sequence details",
  "- Corresponding organism information (as provided in `organisms.txt`)",
  "",
  "### **03_database_taxonomic_tree.txt**",
  "Taxonomic Tree of the content in the database. Size is ",
  "",
  "### **/detected_protein_resouces/**",
  "This directory will contain annotated resources corresponding to the proteins that were detected.")
# Write the content to the specified file
readr::write_lines(readme_content, output_fp)
knitr::knit2html(output_fp,html_fp)
message("README.md has been generated successfully at ", output_fp)
message("README.html has been generated sucessfully at ", html_fp)
